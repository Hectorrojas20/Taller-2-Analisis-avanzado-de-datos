---
title: "Taller 2 AAD"
author: "Hector Rojas y Jorge Esneider Henao"
date: "2023-04-20"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r}
options(repos = "http://cran.rstudio.com")
install.packages("mgcv")
install.packages("caret")  # Install the caret package
library(caret)            # Load the caret package
library(ISLR2)
library(boot)
library(splines)
library(mgcv)
library(gam)
library(glmnet)
library(ISLR)

```

```{r}
datos<-Auto
head(datos)
```

```{r}
# Crear un nuevo data frame con solo las columnas x e y
nueva_data2 <- data.frame(hp = datos$horsepower, mpg = datos$mpg)
```

***Problema 1***

1.  **Separe aleatoriamente (pero guarde la semilla) su conjunto de datos en dos partes:**

    **Entrenamiento: 90% de los autos.**

    **Prueba: 10% de los autos.**

```{r}
# Establecer una semilla para reproducibilidad
set.seed(123)

# Dividir aleatoriamente los datos en conjuntos de entrenamiento y prueba
train_indices_autos <- sample(nrow(nueva_data2), round(0.9 * nrow(nueva_data2)))
train_autos <- nueva_data2[train_indices_autos, ]
test_autos <- nueva_data2[-train_indices_autos, ]

# Imprimir las dimensiones de los conjuntos de datos resultantes
cat("Training dataset dimensions:", dim(train_autos), "\n")
cat("Testing dataset dimensions:", dim(test_autos), "\n")
```

```{r}
plot(nueva_data2)
```

2.  **Usando los datos de entrenamiento Mediante validación cruzada en 10 folds, determine el número óptimo de knots para el problema de regresión spline. Considere como número de posible de knots 1,...,10, igualmente espaciados en el rango de la variable horsepower. ¿Qué modelo (es decir, cual valor de knot con k = 1, ..., 10) resulta en un menor ECM de predición?**

```{r}
# Definir el número de folds para la validación cruzada
k <- 10

# Definir el rango de grados de libertad para el spline natural
df_range_autos <- seq(2, 10, by = 1)

# Dividir los datos en k folds
folds <- createFolds(nueva_data2$hp, k = k)

# Inicializar un vector para almacenar los errores cuadráticos medios
mse <- rep(0, length(df_range_autos))

# Ciclo sobre cada valor de grados de libertad y realizar validación cruzada
for (i in 1:length(df_range_autos)) {
  mse_fold <- rep(0, k)
  for (j in 1:k) {
    # Obtener los datos de entrenamiento y prueba para este fold
    train <- nueva_data2[-folds[[i]], ]
    test <- nueva_data2[folds[[i]], ]
    # Ajustar el modelo utilizando los datos de entrenamiento y evaluar en los datos de prueba
    model <- lm(mpg ~ s(hp, df = df_range_autos[i]), data = train)
    pred <- predict(model, newdata = test)
    mse_fold[j] <- mean((test$mpg  - pred)^2)
  }
  # Promediar los errores cuadráticos medios a través de los folds
  mse[i] <- mean(mse_fold)
}

# Encontrar el número de grados de libertad que minimiza el error cuadrático medio
opt_df <- df_range_autos[which.min(mse)]
mse_opt <- min(mse)

# Imprimir el número óptimo de grados de libertad y el mínimo error cuadrático medio
cat("El número óptimo de grados de libertad es", opt_df, "con un error cuadrático medio mínimo de", mse_opt)
print(mse)

```

El modelo que resultó en un menor ECM de predicción fue aquel que utilizó un número de knots igual a 3, donde 3 es el valor de knots que minimizó el MSE durante la validación cruzada. Por lo tanto, se recomienda utilizar un modelo de regresión spline con X knots para predecir los valores de la variable de interés

3.  **Usando los datos de entrenamiento, determine el mejor modelo basado en base de funciones Compare el poder de predicción de los modelos: polinomio grado 2 global, spline suavizado y del modelo de regresión spline óptimo (encontrado en el punto anterior) utilizando validación cruzada en 10 folds. ¿Cuál de los tres modelos seleccionaría basado en el ECM de predición?.**

```{r}
# definiendo el modelo polinomial de grado 2
poly_model <- lm(mpg ~ poly(hp, 2), data = train)
poly_pred <- predict(poly_model, newdata = test)
poly_mse <- mean((test$mpg - poly_pred)^2)
cat("MSE para el modelo pilinomial de grado 2:", poly_mse, "\n")

```

```{r}
# Modelo Spline smoothing
spline_model <- lm(mpg ~ ns(hp, df = opt_df), data = train)
spline_pred <- predict(spline_model, newdata = test)
spline_mse <- mean((test$mpg - spline_pred)^2)
cat("MSE para Modelo Spline smoothing:", spline_mse, "\n")

```

```{r}
# Modelo optimal Spline
opt_spline_model <- lm(mpg ~ bs(hp, df = opt_df), data = train)
opt_spline_pred <- predict(opt_spline_model, newdata = test)
opt_spline_mse <- mean((test$mpg - opt_spline_pred)^2)
cat("MSE para modelo optimal Spline:", opt_spline_mse, "\n")
```

el mejor modelo dado los modelos mostrados es el Spline smoothing que tiene un error de 32.24 de MSE

4.  **Usando los datos de entrenamiento, determine el mejor modelo basado en regresión local Determine la regresión polinomial local con kernel gaussiano que resulte en menor error de predicción: regresión de grado 0, 1 o 2. Use el ancho de banda óptimo dado por defecto por la función loess().**

```{r}
# Ajustar modelos de regresión polinomial local de grado 0, 1 y 2
degree0_model <- loess(mpg ~ hp, data = train_autos, degree = 0)
degree1_model <- loess(mpg ~ hp, data = train_autos, degree = 1)
degree2_model <- loess(mpg ~ hp, data = train_autos, degree = 2)

# Predecir usando cada modelo y calcular el error cuadrático medio en el conjunto de prueba
degree0_pred <- predict(degree0_model, newdata = test_autos)
degree1_pred <- predict(degree1_model, newdata = test_autos)
degree2_pred <- predict(degree2_model, newdata = test_autos)

degree0_mse <- mean((test_autos$mpg - degree0_pred)^2)
degree1_mse <- mean((test_autos$mpg - degree1_pred)^2)
degree2_mse <- mean((test_autos$mpg - degree2_pred)^2)

# Determinar el modelo con el menor error cuadrático medio
mse <- c(degree0_mse, degree1_mse, degree2_mse)
opt_degree <- which.min(mse)

# Imprimir el modelo óptimo y su error cuadrático medio
cat("El modelo optimo de regresion polinomial local tiene grado", opt_degree, "con un MSE de", mse[opt_degree], "\n")
```

5.  **Usando los datos de entrenamiento y de prueba, determine el mejor de los tres paradigmas de modelamiento Ajuste el mejor modelo basado en base de funciones, el mejor modelo basado en regresión local y un polinomio global de grado dos con los datos de entrenamiento y calcule el ECM de prueba para cada modelo.**

```{r}

cat("MSE para modelo polinomial de grado 2:", poly_mse, "\n")


cat("MSE para modelo optimal spline:", opt_spline_mse, "\n")


cat("MSE para modelo spline smoothing:", spline_mse, "\n")
```

**Repita (1) - (5) un total de 10 veces de manera que en el paso (1) conforme una nueva muestra de validación cruzada, esto le permitirá obtener 10 ECM de prueba para cada paradigma de modelamiento. Grafique las tres distribuciones del ECM de prueba y responda ¿Cuál acercmiento seleccionaría basado en el ECM de predición: basado en base de funciones, basado en regresión local o polinomial global?.**

```{r}
# Crear una función para ajustar y evaluar un modelo usando validación cruzada
  fit_eval_model <- function(model, nueva_data2, k = 10) {
  # Dividir los datos en k folds
  folds <- createFolds(nueva_data2$mpg, k = k)
  
  # Inicializar un vector para almacenar los errores cuadrados medios
  mse <- rep(0, k)
  
  # Iterar sobre cada fold y realizar la validación cruzada
  for (i in 1:k) {
    #  Obtener los datos de entrenamiento y prueba para este fold
    train <- unlist(folds[-i])
    test <- folds[[i]]
    
    # Ajustar el modelo usando los datos de entrenamiento y evaluarlo en los datos de prueba
    model_fit <- model(train)
    pred <- predict(model_fit, newdata = test_autos)
    mse[i] <- mean((test_autos$mpg - pred)^2)
  }
  
  # Devolver el error cuadratico medio
  return(mean(mse))
}

# Definir los modelos a evaluar
models <- list(
  "Funcion base" = function(data) lm(mpg ~ hp, data = nueva_data2),
  "Regresion Local" = function(data) loess(mpg ~ hp, data = nueva_data2),
  "Regresion polinomial grado 2" = function(data) lm(mpg ~ poly(hp, 2), data = nueva_data2)
)

# Inicializar un vector para almacenar los errores cuadraticos medios en prueba para cada modelo
test_mse <- matrix(NA, nrow = 10, ncol = length(models))

# Iterar 10 veces la validación cruzada y evaluar cada modelo
for (i in 1:10) {
  # Dividir aleatoriamente los datos en conjuntos de entrenamiento y prueba
  train_indices <- sample(nrow(nueva_data2), round(0.9 * nrow(nueva_data2)))
  train_data <- nueva_data2[train_indices, ]
  test_data <- nueva_data2[-train_indices, ]
  
  # Evaluar cada modelo en los datos de prueba y almacenar los resultados
  for (j in 1:length(models)) {
    test_mse[i, j] <- fit_eval_model(models[[j]], train_data, k = 10)
  }
}

# Crear un boxplot de caja de los errores cuadraticos medios en prueba para cada modelo
boxplot(test_mse, main = "Test MSEs for different models", ylab = "MSE", names = names(models))

# Calcular la mediana de los errores cuadraticos medios en prueba para cada modelo
median_mse <- apply(test_mse, 2, median)

# Imprimir la mediana de los errores cuadraticos medios en prueba para cada modelo
cat("Median test MSEs:\n")
cat(paste0(names(models), ": ", median_mse, "\n"))


```

Basado en los acercamiento seleccionamos el modelo basado en regresion local ya que minimiza el MSE

***Problema 2***

![](Pregunta%201.png)

El estimador de Nadarya-Watson para la i-ésima unidad estadística en el punto t se define como sigue:

![](imagen%202.png)

donde Yi es la observación de la función Y en el punto Xi , K es una función núcleo simétrica y suave, h es el ancho de banda o ventana de suavizado y n es el número de observaciones para la i-ésima unidad estadística.

Este estimador se basa en la idea de suavizar la función mediante la combinación lineal ponderada de las observaciones cercanas, utilizando una función núcleo para dar mayor peso a las observaciones más cercanas en el intervalo de suavizado.

![](pregunta%202.png)

Este estimador se basa en la idea de suavizar la función media mediante la combinación lineal ponderada de todas las observaciones cercanas en el intervalo de suavizado, utilizando una función núcleo para dar mayor peso a las observaciones más cercanas. Demir and Toktamiş (2010)

![](imagen%203.png)

**Bibliografia**:

-   Demir, Serdar & Toktamis, Oniz. (2010). On The Adaptive Nadaraya-Watson Kernel Regression Estimators. Hacettepe Journal of Mathematics and Statistics. 39. 429-437.

-   Watson, G. S. (1964). Smooth Regression Analysis. Sankhyā: The Indian Journal of Statistics, Series A (1961-2002), 26(4), 359--372. <http://www.jstor.org/stable/25049340>

-   Cornistein, Romina (2013). Estimadores de Naradaya Watson aplicados a datos funcionales. Universidad de Buenos Aires, recuperado de <https://web.dm.uba.ar/files/tesis_lic/2013/romina_cornistein.pdf>

-   Demir S, Toktamiş Ö (2010). On the Adaptive Nadaraya-Watson Kernel
    Regression Estimators. Hacettepe J. Math. Stat. 39(3):429-437. recuperado de <https://dergipark.org.tr/tr/download/article-file/86715>
